server:
  port: 8081

spring:
  kafka:
    bootstrap-servers: 192.168.75.132:9092 # kafka代理地址
    producer:
      retries: 0  #消息发送失败重试次数
      batch-size: 16384  # 每次批量发送消息的数量
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
        # acks=0：生产者把消息发送到broker即认为成功，不等待broker的处理结果。这种方式的吞吐最高，但也是最容易丢失消息的。
        # acks=1：生产者会在该分区的群首（leader）写入消息并返回成功后，认为消息发送成功。如果群首写入消息失败，生产者会收到错误响应并进行重试。这种方式能够一定程度避免消息丢失，但如果群首宕机时该消息没有复制到其他副本，那么该消息还是会丢失。另外，如果我们使用同步方式来发送，延迟会比前一种方式大大增加（至少增加一个网络往返时间）；如果使用异步方式，应用感知不到延迟，吞吐量则会受异步正在发送中的数量限制。
        # acks=all：生产者会等待所有副本成功写入该消息，这种方式是最安全的，能够保证消息不丢失，但是延迟也是最大的。


    # 消费者

    consumer:
      group-id: user-log-group  # 消费者消费所在组
      auto-offset-reset: earliest
      # earliest
      # 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest  默认
      # 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none
      # topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常

      enable-auto-commit: true  # 自动提交
      auto-commit-interval: 100 #  每100ms提交一次偏移
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

